{
	"cells": [
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# BertonGan MNIST experiments\n",
				"\n",
				"### Overview\n",
				"\n",
				"This notebook will take you through the following using the MNIST dataset:\n",
				"\n",
				"- loading in the MNIST dataset\n",
				"- instantiating BertonGan + what a BeronGan is\n",
				"- training a BertonGan + how the training procedure works\n",
				"- using a BertonGan for inference\n",
				"- using a BertonGan for style transfer"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"# setup our environment to work with colab (if we are using it)\n",
				"\n",
				"import sys\n",
				"IN_COLAB = 'google.colab' in sys.modules\n",
				"if IN_COLAB:\n",
				"\t!git clone https://github.com/Herb-Wright/berton-gan/\n",
				"\t!mv berton-gan berton_gan\n",
				"\timport os\n",
				"\tsys.path.append(os.path.abspath('berton_gan'))\n",
				"\n",
				"import torch\n",
				"DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## Loading in the MNIST dataset\n",
				"\n",
				"And displaying the first $K$ images"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"from src import download_mnist_data\n",
				"from experiments import show_images\n",
				"\n",
				"# this is how we download mnist data\n",
				"training_data = download_mnist_data()\n",
				"testing_data = download_mnist_data(train=False)\n",
				"\n",
				"# display first K images\n",
				"K = 25\n",
				"\n",
				"show_images([training_data[i][0] for i in range(K)], grayscale=True)\n"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## Creating the 'mnist' BertonGan\n",
				"\n",
				"A BertonGan has five different networks:\n",
				"\n",
				"- face encoder ($f_F: \\mathbb R^{d} \\rightarrow \\mathbb R^{H_F}$): takes in $n$ images of class $A$ ($F_A \\in \\mathbb R^{n \\times d}$) and returns a latent vector $h_F \\in \\mathbb R^{H_F}$ by average pooling each image's corresponding latent vector\n",
				"- image encoder ($f_I: \\mathbb R^d \\rightarrow \\mathbb R^{H_I}$): takes in $N$ images of any class and returns $N$ latent representations of the image.\n",
				"- image decoder\n",
				"- discriminator1\n",
				"- discriminator2"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### Constructing our BertonGan\n",
				"\n",
				"Next, we must make our BertonGan, and store it in a variable"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"from src import BertonGan\n",
				"\n",
				"# we make our BertonGan! (and put on device)\n",
				"berton_gan = BertonGan('mnist')\n",
				"\n",
				"print(berton_gan.face_encoder)\n",
				"print(berton_gan.image_encoder)\n",
				"print(berton_gan.image_decoder)\n",
				"print(berton_gan.discriminator1)\n",
				"print(berton_gan.discriminator2)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## Training our BertonGan on MNIST\n",
				"\n",
				"training a BertonGan takes a long time and careful adjustments, so it is unlikely yours will turn out that good in only 10 epochs"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### Training the BertonGan\n",
				"\n",
				"Next, we train our BertonGan!"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"from src import train_all_at_once, MnistLoader\n",
				"\n",
				"# set to false to not train the gan\n",
				"TRAIN_BERTONGAN = True\n",
				"\n",
				"if TRAIN_BERTONGAN:\n",
				"\t# here we train our berton_gan\n",
				"\tn, N, learning_rate, epochs = 3, 32, 1e-2, 10\n",
				"\tdataloader = MnistLoader(3, 32)\n",
				"\ttrain_all_at_once(berton_gan, dataloader, epochs, optimizer_options={'lr': learning_rate}, verbose=True)\n"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### Loading in berton_gan from file"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"from experiments.utils import load_berton_gan\n",
				"\n",
				"if not TRAIN_BERTONGAN:\n",
				"\tberton_gan = load_berton_gan('mnist_experiment_herb_8/49')"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## Using BertonGan for inference\n",
				"\n",
				"The process for using BertonGan for inference is:\n",
				"\n",
				"1. loop through training data and find average latent vectors for each class (digits 1-10)\n",
				"   - in our code, we approximate this with a number of random indexes of the training data instead of the whole thing\n",
				"2. loop through testing data and classify each test image with the following:\n",
				"   1. calculating scores by running discriminator2 on the image for each latent encoding\n",
				"   2. class corresponding to latent encoding with highest score is the prediction\n",
				"\n",
				"The pretrained model should achieve about $97$% accuracy."
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"from tqdm import tqdm, trange\n",
				"\n",
				"# set berton_gan to eval mode\n",
				"berton_gan.eval()\n",
				"\n",
				"# build our latent vectors\n",
				"N = 5000 # we approximate our training data with N random samples for speed purposes\n",
				"idxs = torch.randint(0, len(training_data), (N, 1))\n",
				"style_encodings = torch.zeros((10, 2), device=DEVICE)\n",
				"counts = torch.zeros((10,), device=DEVICE)\n",
				"for i in trange(\n",
				"\tN,\n",
				"\tdesc='computing latent vectors for training data'\n",
				"):\n",
				"\tx_i, y_i = training_data[idxs[i].squeeze()]\n",
				"\tx_i = x_i.to(DEVICE)\n",
				"\tcounts[y_i] += 1\n",
				"\tstyle_encodings[y_i] += berton_gan.face_encoder(x_i.unsqueeze(0)).squeeze()\n",
				"style_encodings /= counts.unsqueeze(1)\n",
				"\n",
				"print(f'our latent encodings are {style_encodings}')\n",
				"\n",
				"# go through test set and see accuracy\n",
				"correct, total = 0, 0\n",
				"for i in trange(\n",
				"\tlen(testing_data),\n",
				"\tdesc='evaluating on test data'\n",
				"):\n",
				"\tx_i, y_i = testing_data[i]\n",
				"\tx_i = x_i.to(DEVICE)\n",
				"\ttotal += 1\n",
				"\tscores = torch.zeros(10, device=DEVICE)\n",
				"\tfor i in range(10):\n",
				"\t\tscores[i] = berton_gan.shares_style_latent(x_i, style_encodings[i])\n",
				"\tif torch.argmax(scores) == y_i:\n",
				"\t\tcorrect += 1\n",
				"\n",
				"# print our result\n",
				"print(f'The BertonGan acheived {correct / total} accuracy on test data')"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## Using BertonGan for style transfer\n",
				"\n",
				"We conduct style transfer by inputting our style image into the face encoder network, and inputting our content image into the image encoder, then passing our latent embeddings into our image decoder network.\n",
				"\n",
				"In the output of the code before the order of the images is [content] + [style] = [result]. The style and result should have the same number, and the content and result image should be close in l2 distance. "
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"from random import randint\n",
				"\n",
				"berton_gan.eval()\n",
				"\n",
				"imgs = []\n",
				"for i in range(12):\n",
				"\t# pick a content image\n",
				"\tcontent_img, _ = testing_data[randint(0, len(testing_data))]\n",
				"\timgs.append(content_img)\n",
				"\n",
				"\t# pick a style image\n",
				"\tstyle_img, _ = testing_data[randint(0, len(testing_data))]\n",
				"\timgs.append(style_img)\n",
				"\n",
				"\t# generate new image\n",
				"\tnew_img = berton_gan.generate_image(style_img.to(DEVICE), content_img.to(DEVICE))\n",
				"\timgs.append(new_img)\n",
				"\n",
				"print(f'columns 1 and 4 are content; columns 2 and 5 are style; columns 3 and 6 are result')\n",
				"show_images(imgs, grayscale=True)"
			]
		}
	],
	"metadata": {
		"kernelspec": {
			"display_name": "Python 3.10.4 ('school')",
			"language": "python",
			"name": "python3"
		},
		"language_info": {
			"name": "python",
			"version": "3.10.4"
		},
		"orig_nbformat": 4,
		"vscode": {
			"interpreter": {
				"hash": "eafad1310361ab8e4c95ffa136f245d33cf427639dfd67e3b17696128ee3b131"
			}
		}
	},
	"nbformat": 4,
	"nbformat_minor": 2
}
