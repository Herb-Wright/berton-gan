{
	"cells": [
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"# BertonGan MNIST experiments\n",
				"\n",
				"### Overview\n",
				"\n",
				"This notebook will take you through the following using the MNIST dataset:\n",
				"\n",
				"- loading in the MNIST dataset\n",
				"- instantiating BertonGan + what a BeronGan is\n",
				"- training a BertonGan + how the training procedure works\n",
				"- using a BertonGan for inference\n",
				"- using a BertonGan for style transfer"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 7,
			"metadata": {},
			"outputs": [],
			"source": [
				"# setup our environment to work with colab (if we are using it)\n",
				"\n",
				"import sys\n",
				"IN_COLAB = 'google.colab' in sys.modules\n",
				"if IN_COLAB:\n",
				"\t!git clone https://github.com/Herb-Wright/berton-gan/\n",
				"\t!mv berton-gan berton_gan\n",
				"\timport os\n",
				"\tsys.path.append(os.path.abspath('berton_gan'))\n",
				"\n",
				"import torch\n",
				"DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## Loading in the MNIST dataset\n",
				"\n",
				"And displaying the first $K$ images"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 10,
			"metadata": {},
			"outputs": [
				{
					"ename": "TypeError",
					"evalue": "empty() received an invalid combination of arguments - got (tuple, dtype=NoneType, device=NoneType), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.memory_format memory_format, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of SymInts size, *, torch.memory_format memory_format, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n",
					"output_type": "error",
					"traceback": [
						"\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
						"\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
						"Cell \u001b[1;32mIn [10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m \u001b[39mimport\u001b[39;00m download_mnist_data\n\u001b[0;32m      2\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mthisran\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mexperiments\u001b[39;00m \u001b[39mimport\u001b[39;00m show_images\n",
						"File \u001b[1;32mc:\\Users\\legol\\OneDrive\\Desktop\\School Stuff\\CS5353\\berton-gan\\src\\__init__.py:6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdata_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m download_mnist_data, MnistLoader\n\u001b[0;32m      5\u001b[0m \u001b[39m# the BertonGan networks\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mnetworks\u001b[39;00m \u001b[39mimport\u001b[39;00m BertonGan\n\u001b[0;32m      8\u001b[0m \u001b[39m# training code\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtraining\u001b[39;00m \u001b[39mimport\u001b[39;00m train_all_at_once\n",
						"File \u001b[1;32mc:\\Users\\legol\\OneDrive\\Desktop\\School Stuff\\CS5353\\berton-gan\\src\\networks.py:142\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfaceEncoder\u001b[39m():\n\u001b[0;32m     67\u001b[0m \t\u001b[39mreturn\u001b[39;00m nn\u001b[39m.\u001b[39mSequential(\n\u001b[0;32m     68\u001b[0m \t\tnn\u001b[39m.\u001b[39mConv2d(\u001b[39m1\u001b[39m,\u001b[39m32\u001b[39m,\u001b[39m5\u001b[39m,\u001b[39m1\u001b[39m),\n\u001b[0;32m     69\u001b[0m \t\tnn\u001b[39m.\u001b[39mLeakyReLU(\u001b[39m0.01\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     77\u001b[0m \t\tnn\u001b[39m.\u001b[39mLinear(\u001b[39m4\u001b[39m\u001b[39m*\u001b[39m\u001b[39m4\u001b[39m\u001b[39m*\u001b[39m\u001b[39m64\u001b[39m,\u001b[39m2\u001b[39m)\n\u001b[0;32m     78\u001b[0m \t)\n\u001b[0;32m     80\u001b[0m networks \u001b[39m=\u001b[39m {\n\u001b[0;32m     81\u001b[0m \t\u001b[39m'\u001b[39m\u001b[39mmnist\u001b[39m\u001b[39m'\u001b[39m: {\n\u001b[0;32m     82\u001b[0m \t\t\u001b[39m'\u001b[39m\u001b[39mface_encoder\u001b[39m\u001b[39m'\u001b[39m: faceEncoder(), \u001b[39m# nn.Sequential or something: CNN: 28x28x1 --> 2\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \t\t\u001b[39m'\u001b[39m\u001b[39mimage_encoder\u001b[39m\u001b[39m'\u001b[39m: ConcatHelper(nn\u001b[39m.\u001b[39mSequential(\n\u001b[0;32m     84\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mConv2d(\u001b[39m1\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m),\n\u001b[0;32m     85\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mLeakyReLU(\u001b[39m0.01\u001b[39m),\n\u001b[0;32m     86\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mMaxPool2d(\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m),\n\u001b[0;32m     87\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mConv2d(\u001b[39m8\u001b[39m, \u001b[39m16\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m),\n\u001b[0;32m     88\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mLeakyReLU(\u001b[39m0.01\u001b[39m),\n\u001b[0;32m     89\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mConv2d(\u001b[39m16\u001b[39m, \u001b[39m32\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m),\n\u001b[0;32m     90\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mLeakyReLU(\u001b[39m0.01\u001b[39m),\n\u001b[0;32m     91\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mMaxPool2d(\u001b[39m2\u001b[39m,\u001b[39m2\u001b[39m)\n\u001b[0;32m     92\u001b[0m \t)), \u001b[39m# FCNN: 28x28x1 --> some feature map (maybe 7x7x8)\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \t\t\u001b[39m'\u001b[39m\u001b[39mimage_decoder\u001b[39m\u001b[39m'\u001b[39m: ConcatHelper(nn\u001b[39m.\u001b[39mSequential(\n\u001b[0;32m     94\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mConv2d(\u001b[39m34\u001b[39m, \u001b[39m128\u001b[39m, kernel_size\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msame\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[0;32m     95\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mReLU(),\n\u001b[0;32m     96\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mConv2d(\u001b[39m128\u001b[39m, \u001b[39m128\u001b[39m, kernel_size\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msame\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[0;32m     97\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mReLU(),\n\u001b[0;32m     98\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mConv2d(\u001b[39m128\u001b[39m, \u001b[39m32\u001b[39m, kernel_size\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msame\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[0;32m     99\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mReLU(),\n\u001b[0;32m    100\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mConvTranspose2d(\u001b[39m32\u001b[39m, \u001b[39m16\u001b[39m, (\u001b[39m4\u001b[39m, \u001b[39m4\u001b[39m), \u001b[39m2\u001b[39m, padding\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m),\n\u001b[0;32m    101\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mReLU(),\n\u001b[0;32m    102\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mConv2d(\u001b[39m16\u001b[39m, \u001b[39m16\u001b[39m, kernel_size\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msame\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[0;32m    103\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mReLU(),\n\u001b[0;32m    104\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mConvTranspose2d(\u001b[39m16\u001b[39m, \u001b[39m1\u001b[39m, (\u001b[39m4\u001b[39m, \u001b[39m4\u001b[39m), \u001b[39m2\u001b[39m, padding\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m),\n\u001b[0;32m    105\u001b[0m \t\t\t\u001b[39m# nn.Tanh(),\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mSigmoid(),\n\u001b[0;32m    107\u001b[0m \t\t)), \u001b[39m# FCNN: (feature map) x 2 --> 28x28x1\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \t\t\u001b[39m'\u001b[39m\u001b[39mdiscriminator1\u001b[39m\u001b[39m'\u001b[39m: nn\u001b[39m.\u001b[39mSequential(\n\u001b[0;32m    109\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mConv2d(\u001b[39m1\u001b[39m, \u001b[39m32\u001b[39m, kernel_size\u001b[39m=\u001b[39m(\u001b[39m5\u001b[39m, \u001b[39m5\u001b[39m)),\n\u001b[0;32m    110\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mLeakyReLU(\u001b[39m0.01\u001b[39m),\n\u001b[0;32m    111\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mMaxPool2d((\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m)),\n\u001b[0;32m    112\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mConv2d(\u001b[39m32\u001b[39m, \u001b[39m64\u001b[39m, kernel_size\u001b[39m=\u001b[39m(\u001b[39m5\u001b[39m, \u001b[39m5\u001b[39m)),\n\u001b[0;32m    113\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mLeakyReLU(\u001b[39m0.01\u001b[39m),\n\u001b[0;32m    114\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mMaxPool2d((\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m)),\n\u001b[0;32m    115\u001b[0m \t\t\tFlatten(),\n\u001b[0;32m    116\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mLinear(\u001b[39m64\u001b[39m \u001b[39m*\u001b[39m \u001b[39m4\u001b[39m \u001b[39m*\u001b[39m \u001b[39m4\u001b[39m, \u001b[39m64\u001b[39m \u001b[39m*\u001b[39m \u001b[39m4\u001b[39m \u001b[39m*\u001b[39m \u001b[39m4\u001b[39m),\n\u001b[0;32m    117\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mLeakyReLU(\u001b[39m0.01\u001b[39m),\n\u001b[0;32m    118\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mLinear(\u001b[39m64\u001b[39m \u001b[39m*\u001b[39m \u001b[39m4\u001b[39m \u001b[39m*\u001b[39m \u001b[39m4\u001b[39m, \u001b[39m64\u001b[39m \u001b[39m*\u001b[39m \u001b[39m4\u001b[39m \u001b[39m*\u001b[39m \u001b[39m4\u001b[39m),\n\u001b[0;32m    119\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mLeakyReLU(\u001b[39m0.01\u001b[39m),\n\u001b[0;32m    120\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mLinear(\u001b[39m64\u001b[39m \u001b[39m*\u001b[39m \u001b[39m4\u001b[39m \u001b[39m*\u001b[39m \u001b[39m4\u001b[39m, \u001b[39m10\u001b[39m),\n\u001b[0;32m    121\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mLeakyReLU(\u001b[39m0.01\u001b[39m),\n\u001b[0;32m    122\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mLinear(\u001b[39m10\u001b[39m, \u001b[39m1\u001b[39m),\n\u001b[0;32m    123\u001b[0m \t\t\t\u001b[39m# nn.Sigmoid(),\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \t\t), \u001b[39m# CNN: (28x28x1) --> 1\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \t\t\u001b[39m'\u001b[39m\u001b[39mdiscriminator2\u001b[39m\u001b[39m'\u001b[39m: ConcatHelper(nn\u001b[39m.\u001b[39mSequential(\n\u001b[0;32m    126\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mConv2d(\u001b[39m3\u001b[39m, \u001b[39m32\u001b[39m, kernel_size\u001b[39m=\u001b[39m(\u001b[39m5\u001b[39m, \u001b[39m5\u001b[39m)),\n\u001b[0;32m    127\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mLeakyReLU(\u001b[39m0.01\u001b[39m),\n\u001b[0;32m    128\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mMaxPool2d((\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m)),\n\u001b[0;32m    129\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mConv2d(\u001b[39m32\u001b[39m, \u001b[39m64\u001b[39m, kernel_size\u001b[39m=\u001b[39m(\u001b[39m5\u001b[39m, \u001b[39m5\u001b[39m)),\n\u001b[0;32m    130\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mLeakyReLU(\u001b[39m0.01\u001b[39m),\n\u001b[0;32m    131\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mMaxPool2d((\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m)),\n\u001b[0;32m    132\u001b[0m \t\t\tFlatten(),\n\u001b[0;32m    133\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mLinear(\u001b[39m64\u001b[39m \u001b[39m*\u001b[39m \u001b[39m4\u001b[39m \u001b[39m*\u001b[39m \u001b[39m4\u001b[39m, \u001b[39m64\u001b[39m \u001b[39m*\u001b[39m \u001b[39m4\u001b[39m \u001b[39m*\u001b[39m \u001b[39m4\u001b[39m),\n\u001b[0;32m    134\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mLeakyReLU(\u001b[39m0.01\u001b[39m),\n\u001b[0;32m    135\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mLinear(\u001b[39m64\u001b[39m \u001b[39m*\u001b[39m \u001b[39m4\u001b[39m \u001b[39m*\u001b[39m \u001b[39m4\u001b[39m, \u001b[39m1\u001b[39m),\n\u001b[0;32m    136\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mSigmoid(),\n\u001b[0;32m    137\u001b[0m \t\t)), \u001b[39m# CNN: (28x28x1) x 2\t--> 1\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \t},\n\u001b[0;32m    139\u001b[0m \t\u001b[39m'\u001b[39m\u001b[39mceleba\u001b[39m\u001b[39m'\u001b[39m: {\n\u001b[0;32m    140\u001b[0m \t\t\u001b[39m'\u001b[39m\u001b[39mface_encoder\u001b[39m\u001b[39m'\u001b[39m: nn\u001b[39m.\u001b[39mSequential(\n\u001b[0;32m    141\u001b[0m \t\t\tinitial_celeb(\u001b[39m4\u001b[39m), \n\u001b[1;32m--> 142\u001b[0m \t\t\tceleb_block(\u001b[39m4\u001b[39;49m, \u001b[39m8\u001b[39;49m),\n\u001b[0;32m    143\u001b[0m \t\t\tceleb_block(\u001b[39m8\u001b[39m, \u001b[39m16\u001b[39m),\n\u001b[0;32m    144\u001b[0m \t\t\tceleb_block(\u001b[39m16\u001b[39m, \u001b[39m32\u001b[39m),\n\u001b[0;32m    145\u001b[0m \t\t\tceleb_block(\u001b[39m32\u001b[39m, \u001b[39m64\u001b[39m),\n\u001b[0;32m    146\u001b[0m \t\t\tlast_celeb(\u001b[39m64\u001b[39m)\n\u001b[0;32m    147\u001b[0m \t\t\t),\n\u001b[0;32m    148\u001b[0m \t\t\u001b[39m'\u001b[39m\u001b[39mimage_encoder\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    149\u001b[0m \t\t\u001b[39m'\u001b[39m\u001b[39mimage_decoder\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    150\u001b[0m \t\t\u001b[39m'\u001b[39m\u001b[39mdiscriminator1\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    151\u001b[0m \t\t\u001b[39m'\u001b[39m\u001b[39mdiscriminator2\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    152\u001b[0m \t},\n\u001b[0;32m    153\u001b[0m }\n\u001b[0;32m    155\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mBertonGan\u001b[39;00m():\n\u001b[0;32m    156\u001b[0m \t\u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39mtype\u001b[39m:\u001b[39mstr\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmnist\u001b[39m\u001b[39m'\u001b[39m, device\u001b[39m=\u001b[39mDEVICE):\n",
						"File \u001b[1;32mc:\\Users\\legol\\OneDrive\\Desktop\\School Stuff\\CS5353\\berton-gan\\src\\networks.py:31\u001b[0m, in \u001b[0;36mceleb_block.__init__\u001b[1;34m(self, Cin, Cout)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, Cin, Cout):\n\u001b[0;32m     28\u001b[0m \t\u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[0;32m     30\u001b[0m \t\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnet \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mSequential(\n\u001b[1;32m---> 31\u001b[0m \t\tnn\u001b[39m.\u001b[39;49mConv2d(Cin, Cin\u001b[39m/\u001b[39;49m\u001b[39m4\u001b[39;49m, \u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m),\n\u001b[0;32m     32\u001b[0m \t\tnn\u001b[39m.\u001b[39mLeakyReLU(\u001b[39m0.01\u001b[39m),\n\u001b[0;32m     33\u001b[0m \t\tnn\u001b[39m.\u001b[39mConv2d(Cin\u001b[39m/\u001b[39m\u001b[39m4\u001b[39m, Cin\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m),\n\u001b[0;32m     34\u001b[0m \t\tnn\u001b[39m.\u001b[39mLeakyReLU(\u001b[39m0.01\u001b[39m),\n\u001b[0;32m     35\u001b[0m \t\tnn\u001b[39m.\u001b[39mConv2d(Cin\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m, Cin\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m),\n\u001b[0;32m     36\u001b[0m \t\tnn\u001b[39m.\u001b[39mLeakyReLU(\u001b[39m0.01\u001b[39m), \n\u001b[0;32m     37\u001b[0m \t\tnn\u001b[39m.\u001b[39mConv2d(Cin\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m, Cout, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m     38\u001b[0m \t)\n",
						"File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\conv.py:450\u001b[0m, in \u001b[0;36mConv2d.__init__\u001b[1;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, padding_mode, device, dtype)\u001b[0m\n\u001b[0;32m    448\u001b[0m padding_ \u001b[39m=\u001b[39m padding \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(padding, \u001b[39mstr\u001b[39m) \u001b[39melse\u001b[39;00m _pair(padding)\n\u001b[0;32m    449\u001b[0m dilation_ \u001b[39m=\u001b[39m _pair(dilation)\n\u001b[1;32m--> 450\u001b[0m \u001b[39msuper\u001b[39m(Conv2d, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\n\u001b[0;32m    451\u001b[0m     in_channels, out_channels, kernel_size_, stride_, padding_, dilation_,\n\u001b[0;32m    452\u001b[0m     \u001b[39mFalse\u001b[39;00m, _pair(\u001b[39m0\u001b[39m), groups, bias, padding_mode, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfactory_kwargs)\n",
						"File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\conv.py:137\u001b[0m, in \u001b[0;36m_ConvNd.__init__\u001b[1;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, bias, padding_mode, device, dtype)\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight \u001b[39m=\u001b[39m Parameter(torch\u001b[39m.\u001b[39mempty(\n\u001b[0;32m    135\u001b[0m         (in_channels, out_channels \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m groups, \u001b[39m*\u001b[39mkernel_size), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfactory_kwargs))\n\u001b[0;32m    136\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 137\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight \u001b[39m=\u001b[39m Parameter(torch\u001b[39m.\u001b[39mempty(\n\u001b[0;32m    138\u001b[0m         (out_channels, in_channels \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m groups, \u001b[39m*\u001b[39mkernel_size), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfactory_kwargs))\n\u001b[0;32m    139\u001b[0m \u001b[39mif\u001b[39;00m bias:\n\u001b[0;32m    140\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias \u001b[39m=\u001b[39m Parameter(torch\u001b[39m.\u001b[39mempty(out_channels, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfactory_kwargs))\n",
						"\u001b[1;31mTypeError\u001b[0m: empty() received an invalid combination of arguments - got (tuple, dtype=NoneType, device=NoneType), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.memory_format memory_format, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of SymInts size, *, torch.memory_format memory_format, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n"
					]
				}
			],
			"source": [
				"from src import download_mnist_data\n",
				"from experiments import show_images\n",
				"\n",
				"# this is how we download mnist data\n",
				"training_data = download_mnist_data()\n",
				"testing_data = download_mnist_data(train=False)\n",
				"\n",
				"# display first K images\n",
				"K = 25\n",
				"\n",
				"show_images([training_data[i][0] for i in range(K)], grayscale=True)\n"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## Creating the 'mnist' BertonGan\n",
				"\n",
				"A BertonGan has five different networks:\n",
				"\n",
				"- face encoder ($f_F: \\mathbb R^{d} \\rightarrow \\mathbb R^{H_F}$): takes in $n$ images of class $A$ ($F_A \\in \\mathbb R^{n \\times d}$) and returns a latent vector $h_F \\in \\mathbb R^{H_F}$ by average pooling each image's corresponding latent vector\n",
				"- image encoder ($f_I: \\mathbb R^d \\rightarrow \\mathbb R^{H_I}$): takes in $N$ images of any class and returns $N$ latent representations of the image.\n",
				"- image decoder\n",
				"- discriminator1\n",
				"- discriminator2"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### Constructing our BertonGan\n",
				"\n",
				"Next, we must make our BertonGan, and store it in a variable"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 4,
			"metadata": {},
			"outputs": [
				{
					"ename": "TypeError",
					"evalue": "empty() received an invalid combination of arguments - got (tuple, dtype=NoneType, device=NoneType), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.memory_format memory_format, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of SymInts size, *, torch.memory_format memory_format, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n",
					"output_type": "error",
					"traceback": [
						"\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
						"\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
						"Cell \u001b[1;32mIn [4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m \u001b[39mimport\u001b[39;00m BertonGan\n\u001b[0;32m      3\u001b[0m \u001b[39m# we make our BertonGan! (and put on device)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m berton_gan \u001b[39m=\u001b[39m BertonGan(\u001b[39m'\u001b[39m\u001b[39mmnist\u001b[39m\u001b[39m'\u001b[39m)\n",
						"File \u001b[1;32mc:\\Users\\legol\\OneDrive\\Desktop\\School Stuff\\CS5353\\berton-gan\\src\\__init__.py:6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdata_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m download_mnist_data, MnistLoader\n\u001b[0;32m      5\u001b[0m \u001b[39m# the BertonGan networks\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mnetworks\u001b[39;00m \u001b[39mimport\u001b[39;00m BertonGan\n\u001b[0;32m      8\u001b[0m \u001b[39m# training code\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtraining\u001b[39;00m \u001b[39mimport\u001b[39;00m train_all_at_once\n",
						"File \u001b[1;32mc:\\Users\\legol\\OneDrive\\Desktop\\School Stuff\\CS5353\\berton-gan\\src\\networks.py:142\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfaceEncoder\u001b[39m():\n\u001b[0;32m     67\u001b[0m \t\u001b[39mreturn\u001b[39;00m nn\u001b[39m.\u001b[39mSequential(\n\u001b[0;32m     68\u001b[0m \t\tnn\u001b[39m.\u001b[39mConv2d(\u001b[39m1\u001b[39m,\u001b[39m32\u001b[39m,\u001b[39m5\u001b[39m,\u001b[39m1\u001b[39m),\n\u001b[0;32m     69\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mLeakyReLU(\u001b[39m0.01\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     77\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mLinear(\u001b[39m4\u001b[39m\u001b[39m*\u001b[39m\u001b[39m4\u001b[39m\u001b[39m*\u001b[39m\u001b[39m64\u001b[39m,\u001b[39m2\u001b[39m)\n\u001b[0;32m     78\u001b[0m \t)\n\u001b[0;32m     80\u001b[0m networks \u001b[39m=\u001b[39m {\n\u001b[0;32m     81\u001b[0m \t\u001b[39m'\u001b[39m\u001b[39mmnist\u001b[39m\u001b[39m'\u001b[39m: {\n\u001b[0;32m     82\u001b[0m \t\t\u001b[39m'\u001b[39m\u001b[39mface_encoder\u001b[39m\u001b[39m'\u001b[39m: faceEncoder(), \u001b[39m# nn.Sequential or something: CNN: 28x28x1 --> 2\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \t\t\u001b[39m'\u001b[39m\u001b[39mimage_encoder\u001b[39m\u001b[39m'\u001b[39m: ConcatHelper(nn\u001b[39m.\u001b[39mSequential(\n\u001b[0;32m     84\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mConv2d(\u001b[39m1\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m),\n\u001b[0;32m     85\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mLeakyReLU(\u001b[39m0.01\u001b[39m),\n\u001b[0;32m     86\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mMaxPool2d(\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m),\n\u001b[0;32m     87\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mConv2d(\u001b[39m8\u001b[39m, \u001b[39m16\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m),\n\u001b[0;32m     88\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mLeakyReLU(\u001b[39m0.01\u001b[39m),\n\u001b[0;32m     89\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mConv2d(\u001b[39m16\u001b[39m, \u001b[39m32\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m),\n\u001b[0;32m     90\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mLeakyReLU(\u001b[39m0.01\u001b[39m),\n\u001b[0;32m     91\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mMaxPool2d(\u001b[39m2\u001b[39m,\u001b[39m2\u001b[39m)\n\u001b[0;32m     92\u001b[0m \t)), \u001b[39m# FCNN: 28x28x1 --> some feature map (maybe 7x7x8)\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \t\t\u001b[39m'\u001b[39m\u001b[39mimage_decoder\u001b[39m\u001b[39m'\u001b[39m: ConcatHelper(nn\u001b[39m.\u001b[39mSequential(\n\u001b[0;32m     94\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mConv2d(\u001b[39m34\u001b[39m, \u001b[39m128\u001b[39m, kernel_size\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msame\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[0;32m     95\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mReLU(),\n\u001b[0;32m     96\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mConv2d(\u001b[39m128\u001b[39m, \u001b[39m128\u001b[39m, kernel_size\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msame\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[0;32m     97\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mReLU(),\n\u001b[0;32m     98\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mConv2d(\u001b[39m128\u001b[39m, \u001b[39m32\u001b[39m, kernel_size\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msame\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[0;32m     99\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mReLU(),\n\u001b[0;32m    100\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mConvTranspose2d(\u001b[39m32\u001b[39m, \u001b[39m16\u001b[39m, (\u001b[39m4\u001b[39m, \u001b[39m4\u001b[39m), \u001b[39m2\u001b[39m, padding\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m),\n\u001b[0;32m    101\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mReLU(),\n\u001b[0;32m    102\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mConv2d(\u001b[39m16\u001b[39m, \u001b[39m16\u001b[39m, kernel_size\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msame\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[0;32m    103\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mReLU(),\n\u001b[0;32m    104\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mConvTranspose2d(\u001b[39m16\u001b[39m, \u001b[39m1\u001b[39m, (\u001b[39m4\u001b[39m, \u001b[39m4\u001b[39m), \u001b[39m2\u001b[39m, padding\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m),\n\u001b[0;32m    105\u001b[0m \t\t\t\u001b[39m# nn.Tanh(),\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mSigmoid(),\n\u001b[0;32m    107\u001b[0m \t\t)), \u001b[39m# FCNN: (feature map) x 2 --> 28x28x1\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \t\t\u001b[39m'\u001b[39m\u001b[39mdiscriminator1\u001b[39m\u001b[39m'\u001b[39m: nn\u001b[39m.\u001b[39mSequential(\n\u001b[0;32m    109\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mConv2d(\u001b[39m1\u001b[39m, \u001b[39m32\u001b[39m, kernel_size\u001b[39m=\u001b[39m(\u001b[39m5\u001b[39m, \u001b[39m5\u001b[39m)),\n\u001b[0;32m    110\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mLeakyReLU(\u001b[39m0.01\u001b[39m),\n\u001b[0;32m    111\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mMaxPool2d((\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m)),\n\u001b[0;32m    112\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mConv2d(\u001b[39m32\u001b[39m, \u001b[39m64\u001b[39m, kernel_size\u001b[39m=\u001b[39m(\u001b[39m5\u001b[39m, \u001b[39m5\u001b[39m)),\n\u001b[0;32m    113\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mLeakyReLU(\u001b[39m0.01\u001b[39m),\n\u001b[0;32m    114\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mMaxPool2d((\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m)),\n\u001b[0;32m    115\u001b[0m \t\t\tFlatten(),\n\u001b[0;32m    116\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mLinear(\u001b[39m64\u001b[39m \u001b[39m*\u001b[39m \u001b[39m4\u001b[39m \u001b[39m*\u001b[39m \u001b[39m4\u001b[39m, \u001b[39m64\u001b[39m \u001b[39m*\u001b[39m \u001b[39m4\u001b[39m \u001b[39m*\u001b[39m \u001b[39m4\u001b[39m),\n\u001b[0;32m    117\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mLeakyReLU(\u001b[39m0.01\u001b[39m),\n\u001b[0;32m    118\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mLinear(\u001b[39m64\u001b[39m \u001b[39m*\u001b[39m \u001b[39m4\u001b[39m \u001b[39m*\u001b[39m \u001b[39m4\u001b[39m, \u001b[39m64\u001b[39m \u001b[39m*\u001b[39m \u001b[39m4\u001b[39m \u001b[39m*\u001b[39m \u001b[39m4\u001b[39m),\n\u001b[0;32m    119\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mLeakyReLU(\u001b[39m0.01\u001b[39m),\n\u001b[0;32m    120\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mLinear(\u001b[39m64\u001b[39m \u001b[39m*\u001b[39m \u001b[39m4\u001b[39m \u001b[39m*\u001b[39m \u001b[39m4\u001b[39m, \u001b[39m10\u001b[39m),\n\u001b[0;32m    121\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mLeakyReLU(\u001b[39m0.01\u001b[39m),\n\u001b[0;32m    122\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mLinear(\u001b[39m10\u001b[39m, \u001b[39m1\u001b[39m),\n\u001b[0;32m    123\u001b[0m \t\t\t\u001b[39m# nn.Sigmoid(),\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \t\t), \u001b[39m# CNN: (28x28x1) --> 1\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \t\t\u001b[39m'\u001b[39m\u001b[39mdiscriminator2\u001b[39m\u001b[39m'\u001b[39m: ConcatHelper(nn\u001b[39m.\u001b[39mSequential(\n\u001b[0;32m    126\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mConv2d(\u001b[39m3\u001b[39m, \u001b[39m32\u001b[39m, kernel_size\u001b[39m=\u001b[39m(\u001b[39m5\u001b[39m, \u001b[39m5\u001b[39m)),\n\u001b[0;32m    127\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mLeakyReLU(\u001b[39m0.01\u001b[39m),\n\u001b[0;32m    128\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mMaxPool2d((\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m)),\n\u001b[0;32m    129\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mConv2d(\u001b[39m32\u001b[39m, \u001b[39m64\u001b[39m, kernel_size\u001b[39m=\u001b[39m(\u001b[39m5\u001b[39m, \u001b[39m5\u001b[39m)),\n\u001b[0;32m    130\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mLeakyReLU(\u001b[39m0.01\u001b[39m),\n\u001b[0;32m    131\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mMaxPool2d((\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m)),\n\u001b[0;32m    132\u001b[0m \t\t\tFlatten(),\n\u001b[0;32m    133\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mLinear(\u001b[39m64\u001b[39m \u001b[39m*\u001b[39m \u001b[39m4\u001b[39m \u001b[39m*\u001b[39m \u001b[39m4\u001b[39m, \u001b[39m64\u001b[39m \u001b[39m*\u001b[39m \u001b[39m4\u001b[39m \u001b[39m*\u001b[39m \u001b[39m4\u001b[39m),\n\u001b[0;32m    134\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mLeakyReLU(\u001b[39m0.01\u001b[39m),\n\u001b[0;32m    135\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mLinear(\u001b[39m64\u001b[39m \u001b[39m*\u001b[39m \u001b[39m4\u001b[39m \u001b[39m*\u001b[39m \u001b[39m4\u001b[39m, \u001b[39m1\u001b[39m),\n\u001b[0;32m    136\u001b[0m \t\t\tnn\u001b[39m.\u001b[39mSigmoid(),\n\u001b[0;32m    137\u001b[0m \t\t)), \u001b[39m# CNN: (28x28x1) x 2\t--> 1\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \t},\n\u001b[0;32m    139\u001b[0m \t\u001b[39m'\u001b[39m\u001b[39mceleba\u001b[39m\u001b[39m'\u001b[39m: {\n\u001b[0;32m    140\u001b[0m \t\t\u001b[39m'\u001b[39m\u001b[39mface_encoder\u001b[39m\u001b[39m'\u001b[39m: nn\u001b[39m.\u001b[39mSequential(\n\u001b[0;32m    141\u001b[0m \t\t\tinitial_celeb(\u001b[39m4\u001b[39m), \n\u001b[1;32m--> 142\u001b[0m \t\t\tceleb_block(\u001b[39m4\u001b[39;49m, \u001b[39m8\u001b[39;49m),\n\u001b[0;32m    143\u001b[0m \t\t\tceleb_block(\u001b[39m8\u001b[39m, \u001b[39m16\u001b[39m),\n\u001b[0;32m    144\u001b[0m \t\t\tceleb_block(\u001b[39m16\u001b[39m, \u001b[39m32\u001b[39m),\n\u001b[0;32m    145\u001b[0m \t\t\tceleb_block(\u001b[39m32\u001b[39m, \u001b[39m64\u001b[39m),\n\u001b[0;32m    146\u001b[0m \t\t\tlast_celeb(\u001b[39m64\u001b[39m)\n\u001b[0;32m    147\u001b[0m \t\t\t),\n\u001b[0;32m    148\u001b[0m \t\t\u001b[39m'\u001b[39m\u001b[39mimage_encoder\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    149\u001b[0m \t\t\u001b[39m'\u001b[39m\u001b[39mimage_decoder\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    150\u001b[0m \t\t\u001b[39m'\u001b[39m\u001b[39mdiscriminator1\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    151\u001b[0m \t\t\u001b[39m'\u001b[39m\u001b[39mdiscriminator2\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    152\u001b[0m \t},\n\u001b[0;32m    153\u001b[0m }\n\u001b[0;32m    155\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mBertonGan\u001b[39;00m():\n\u001b[0;32m    156\u001b[0m \t\u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39mtype\u001b[39m:\u001b[39mstr\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmnist\u001b[39m\u001b[39m'\u001b[39m, device\u001b[39m=\u001b[39mDEVICE):\n",
						"File \u001b[1;32mc:\\Users\\legol\\OneDrive\\Desktop\\School Stuff\\CS5353\\berton-gan\\src\\networks.py:31\u001b[0m, in \u001b[0;36mceleb_block.__init__\u001b[1;34m(self, Cin, Cout)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, Cin, Cout):\n\u001b[0;32m     28\u001b[0m \t\u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[0;32m     30\u001b[0m \t\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnet \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mSequential(\n\u001b[1;32m---> 31\u001b[0m \t\tnn\u001b[39m.\u001b[39;49mConv2d(Cin, Cin\u001b[39m/\u001b[39;49m\u001b[39m4\u001b[39;49m, \u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m),\n\u001b[0;32m     32\u001b[0m \t\tnn\u001b[39m.\u001b[39mLeakyReLU(\u001b[39m0.01\u001b[39m),\n\u001b[0;32m     33\u001b[0m \t\tnn\u001b[39m.\u001b[39mConv2d(Cin\u001b[39m/\u001b[39m\u001b[39m4\u001b[39m, Cin\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m),\n\u001b[0;32m     34\u001b[0m \t\tnn\u001b[39m.\u001b[39mLeakyReLU(\u001b[39m0.01\u001b[39m),\n\u001b[0;32m     35\u001b[0m \t\tnn\u001b[39m.\u001b[39mConv2d(Cin\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m, Cin\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m),\n\u001b[0;32m     36\u001b[0m \t\tnn\u001b[39m.\u001b[39mLeakyReLU(\u001b[39m0.01\u001b[39m), \n\u001b[0;32m     37\u001b[0m \t\tnn\u001b[39m.\u001b[39mConv2d(Cin\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m, Cout, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m     38\u001b[0m \t)\n",
						"File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\conv.py:450\u001b[0m, in \u001b[0;36mConv2d.__init__\u001b[1;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, padding_mode, device, dtype)\u001b[0m\n\u001b[0;32m    448\u001b[0m padding_ \u001b[39m=\u001b[39m padding \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(padding, \u001b[39mstr\u001b[39m) \u001b[39melse\u001b[39;00m _pair(padding)\n\u001b[0;32m    449\u001b[0m dilation_ \u001b[39m=\u001b[39m _pair(dilation)\n\u001b[1;32m--> 450\u001b[0m \u001b[39msuper\u001b[39m(Conv2d, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\n\u001b[0;32m    451\u001b[0m     in_channels, out_channels, kernel_size_, stride_, padding_, dilation_,\n\u001b[0;32m    452\u001b[0m     \u001b[39mFalse\u001b[39;00m, _pair(\u001b[39m0\u001b[39m), groups, bias, padding_mode, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfactory_kwargs)\n",
						"File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\conv.py:137\u001b[0m, in \u001b[0;36m_ConvNd.__init__\u001b[1;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, bias, padding_mode, device, dtype)\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight \u001b[39m=\u001b[39m Parameter(torch\u001b[39m.\u001b[39mempty(\n\u001b[0;32m    135\u001b[0m         (in_channels, out_channels \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m groups, \u001b[39m*\u001b[39mkernel_size), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfactory_kwargs))\n\u001b[0;32m    136\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 137\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight \u001b[39m=\u001b[39m Parameter(torch\u001b[39m.\u001b[39mempty(\n\u001b[0;32m    138\u001b[0m         (out_channels, in_channels \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m groups, \u001b[39m*\u001b[39mkernel_size), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfactory_kwargs))\n\u001b[0;32m    139\u001b[0m \u001b[39mif\u001b[39;00m bias:\n\u001b[0;32m    140\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias \u001b[39m=\u001b[39m Parameter(torch\u001b[39m.\u001b[39mempty(out_channels, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfactory_kwargs))\n",
						"\u001b[1;31mTypeError\u001b[0m: empty() received an invalid combination of arguments - got (tuple, dtype=NoneType, device=NoneType), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.memory_format memory_format, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of SymInts size, *, torch.memory_format memory_format, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n"
					]
				}
			],
			"source": [
				"from src import BertonGan\n",
				"\n",
				"# we make our BertonGan! (and put on device)\n",
				"berton_gan = BertonGan('mnist')\n",
				"\n",
				"print(berton_gan.face_encoder)\n",
				"print(berton_gan.image_encoder)\n",
				"print(berton_gan.image_decoder)\n",
				"print(berton_gan.discriminator1)\n",
				"print(berton_gan.discriminator2)"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## Training our BertonGan on MNIST\n",
				"\n",
				"training a BertonGan takes a long time and careful adjustments, so it is unlikely yours will turn out that good in only 10 epochs"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### Training the BertonGan\n",
				"\n",
				"Next, we train our BertonGan!"
			]
		},
		{
			"cell_type": "code",
			"execution_count": 13,
			"metadata": {},
			"outputs": [],
			"source": [
				"from src import train_all_at_once, MnistLoader\n",
				"\n",
				"# set to false to not train the gan\n",
				"TRAIN_BERTONGAN = True\n",
				"\n",
				"if TRAIN_BERTONGAN:\n",
				"\t# here we train our berton_gan\n",
				"\tn, N, learning_rate, epochs = 3, 32, 1e-2, 10\n",
				"\tdataloader = MnistLoader(3, 32)\n",
				"\ttrain_all_at_once(berton_gan, dataloader, epochs, optimizer_options={'lr': learning_rate}, verbose=True)\n"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"### Loading in berton_gan from file"
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"from experiments.utils import load_berton_gan\n",
				"\n",
				"if not TRAIN_BERTONGAN:\n",
				"\tberton_gan = load_berton_gan('mnist_experiment_herb_8/49')"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## Using BertonGan for inference\n",
				"\n",
				"The process for using BertonGan for inference is:\n",
				"\n",
				"1. loop through training data and find average latent vectors for each class (digits 1-10)\n",
				"   - in our code, we approximate this with a number of random indexes of the training data instead of the whole thing\n",
				"2. loop through testing data and classify each test image with the following:\n",
				"   1. calculating scores by running discriminator2 on the image for each latent encoding\n",
				"   2. class corresponding to latent encoding with highest score is the prediction\n",
				"\n",
				"The pretrained model should achieve about $97$% accuracy."
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"from tqdm import tqdm, trange\n",
				"\n",
				"# set berton_gan to eval mode\n",
				"berton_gan.eval()\n",
				"\n",
				"# build our latent vectors\n",
				"N = 5000 # we approximate our training data with N random samples for speed purposes\n",
				"idxs = torch.randint(0, len(training_data), (N, 1))\n",
				"style_encodings = torch.zeros((10, 2), device=DEVICE)\n",
				"counts = torch.zeros((10,), device=DEVICE)\n",
				"for i in trange(\n",
				"\tN,\n",
				"\tdesc='computing latent vectors for training data'\n",
				"):\n",
				"\tx_i, y_i = training_data[idxs[i].squeeze()]\n",
				"\tx_i = x_i.to(DEVICE)\n",
				"\tcounts[y_i] += 1\n",
				"\tstyle_encodings[y_i] += berton_gan.face_encoder(x_i.unsqueeze(0)).squeeze()\n",
				"style_encodings /= counts.unsqueeze(1)\n",
				"\n",
				"print(f'our latent encodings are {style_encodings}')\n",
				"\n",
				"# go through test set and see accuracy\n",
				"correct, total = 0, 0\n",
				"for i in trange(\n",
				"\tlen(testing_data),\n",
				"\tdesc='evaluating on test data'\n",
				"):\n",
				"\tx_i, y_i = testing_data[i]\n",
				"\tx_i = x_i.to(DEVICE)\n",
				"\ttotal += 1\n",
				"\tscores = torch.zeros(10, device=DEVICE)\n",
				"\tfor i in range(10):\n",
				"\t\tscores[i] = berton_gan.shares_style_latent(x_i, style_encodings[i])\n",
				"\tif torch.argmax(scores) == y_i:\n",
				"\t\tcorrect += 1\n",
				"\n",
				"# print our result\n",
				"print(f'The BertonGan acheived {correct / total} accuracy on test data')"
			]
		},
		{
			"cell_type": "markdown",
			"metadata": {},
			"source": [
				"## Using BertonGan for style transfer\n",
				"\n",
				"We conduct style transfer by inputting our style image into the face encoder network, and inputting our content image into the image encoder, then passing our latent embeddings into our image decoder network.\n",
				"\n",
				"In the output of the code before the order of the images is [content] + [style] = [result]. The style and result should have the same number, and the content and result image should be close in l2 distance. "
			]
		},
		{
			"cell_type": "code",
			"execution_count": null,
			"metadata": {},
			"outputs": [],
			"source": [
				"from random import randint\n",
				"\n",
				"berton_gan.eval()\n",
				"\n",
				"imgs = []\n",
				"for i in range(12):\n",
				"\t# pick a content image\n",
				"\tcontent_img, _ = testing_data[randint(0, len(testing_data))]\n",
				"\timgs.append(content_img)\n",
				"\n",
				"\t# pick a style image\n",
				"\tstyle_img, _ = testing_data[randint(0, len(testing_data))]\n",
				"\timgs.append(style_img)\n",
				"\n",
				"\t# generate new image\n",
				"\tnew_img = berton_gan.generate_image(style_img.to(DEVICE), content_img.to(DEVICE))\n",
				"\timgs.append(new_img)\n",
				"\n",
				"print(f'columns 1 and 4 are content; columns 2 and 5 are style; columns 3 and 6 are result')\n",
				"show_images(imgs, grayscale=True)"
			]
		}
	],
	"metadata": {
		"kernelspec": {
			"display_name": "Python 3",
			"language": "python",
			"name": "python3"
		},
		"language_info": {
			"codemirror_mode": {
				"name": "ipython",
				"version": 3
			},
			"file_extension": ".py",
			"mimetype": "text/x-python",
			"name": "python",
			"nbconvert_exporter": "python",
			"pygments_lexer": "ipython3",
			"version": "3.10.9"
		},
		"orig_nbformat": 4,
		"vscode": {
			"interpreter": {
				"hash": "30a1c4f417d4ab3916d57e09b44445a652b38397bf88ca6f4c16140905a5a608"
			}
		}
	},
	"nbformat": 4,
	"nbformat_minor": 2
}
