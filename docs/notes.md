

# MNIST training

- momentum doesn't work that well
- sigmoid outputs for probability are suboptimal
  - saturated gradients leads to failure mode
- square loss functions produce good results
